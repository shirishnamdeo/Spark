import org.apache.spark.h2o._
import org.apache.spark.h2o.{H2OContext, H2OFrame}
import _root_.hex.tree.gbm._

import _root_.hex.tree.gbm.GBMModel
import _root_.hex.tree.gbm.GBMModel .GBMParameters

 
//Why are below imports?
import _root_.water.support.ModelMetricsSupport
import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer}


val h2oContext: H20Context = H2OContext.getOrCreate(sqlContext.sparkContext)


// Generating Train Data
val trainDF = sqlContext.sql("SELECT <selected_columns> FROM <table_name>)
val trainingH2OFrame: H20Frame = h20Context.asH20Frame(trainDF)
val categoricalColumns: Array[String] = Array("<column_name1>", "<column_name12>", ...)
trainingH2OFrame.colToEnum(categoricalColumns)


// Generating Test Data
val testDF = sqlContext.sql("SELECT <selected_columns> FROM <table_name>)
val testH2OFrame: H2OFrame = h2oContext.asH2OFrame(testDF)
val categoricalColumns: Array[String] = Array("<column_name1>", "<column_name12>", ...)
testH2OFrame.colToEnum(categoricalColumns)


val responseColumn = "<response_column_name>"
val trainingColumns: Array[String] = Array("<column_name1>", "<column_name2>", ...)
val ignoredColumns: Array[String] = trainDF.columns.diff(trainingColumns ++ Array(responseColumn))


// GBM Ntree=1, Depth=10
// output: gbm_model


val gbmParameters1: GBMParameters = new GBMParameters()

gbmParameters1._train = trainingH2OFrame._key
gbmParameters1._response_column = responseColumn
gbmParameters1._ignored_columns = ignoredColumns
gbmParameters1._ntrees = 1
gbmParameters1._max_depth = 10

 
val gbm1: GBM = new GBM(gbmParameters1)
val gbm_model = gbm1.trainModel.get


// Generating Predictions And Accuracy 

val predictionH2OFrame = gbm_model.score(testH2OFrame)

testH2OFrame.add(predictionH2OFrame)

testH2OFrame.update()

val test_predictDF = h2oContext.asDataFrame(testH2OFrame)(sqlContext)

test_predictDF.registerTempTable("predict_table")

sqlContext.sql("SELECT SUM(flag)/ COUNT(*) AS accuracy from (SELECT (CASE WHEN <response_column_name> = predict THEN 1 ELSE 0 END ) AS flag from predict_table) AS Flag table").show()