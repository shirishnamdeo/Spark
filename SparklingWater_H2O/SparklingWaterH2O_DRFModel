import org.apache.spark.h2o._
import org.apache.spark.h2o.{H2OContext, H2OFrame}
import _root_.hex.tree.drf._

import _root_.hex.tree.drf.{ DRF, DRFModel }
import _root_.hex.tree.drf.DRFModel .DRFParameters


import _root_.water.support.ModelMetricsSupport
import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer}

val h2oContext: H20Context = H2OContext.getOrCreate(sqlContext.sparkContext)




// Generating Train Data
val trainDF = sqlContext.sql("SELECT <selected_columns> FROM <table_name>)
val trainingH2OFrame: H20Frame = h20Context.asH20Frame(trainDF)
val categoricalColumns: Array[String] = Array("<column_name1>", "<column_name12>", ...)
trainingH2OFrame.colToEnum(categoricalColumns)


// Generating Test Data
val testDF = sqlContext.sql("SELECT <selected_columns> FROM <table_name>)
val testH2OFrame: H2OFrame = h2oContext.asH2OFrame(testDF)
val categoricalColumns: Array[String] = Array("<column_name1>", "<column_name12>", ...)
testH2OFrame.colToEnum(categoricalColumns)


val responseColumn = "<response_column_name>"
val trainingColumns: Array[String] = Array("<column_name1>", "<column_name2>", ...)
val ignoredColumns: Array[String] = trainDF.columns.diff(trainingColumns ++ Array(responseColumn))




// Building Model

val drfParams: GBMParameters = new GBMParameters()

drfParams._train = trainingH2OFrame._key
drfParams._response_column = responseColumn
drfParams._ignored_columns = ignoredColumns
drfParams._ntrees = 1


 
val drf: DRF = new DRF(drf)
val drf_model = drf.trainModel.get




// Generating Predictions And Accuracy 

val predictionH2OFrame = drf_model.score(testH2OFrame)

testH2OFrame.add(predictionH2OFrame)

testH2OFrame.update()

val test_predictDF = h2oContext.asDataFrame(testH2OFrame)(sqlContext)

test_predictDF.registerTempTable("predict_table")

sqlContext.sql("SELECT SUM(flag)/ COUNT(*) AS accuracy from (SELECT (CASE WHEN <response_column_name> = predict THEN 1 ELSE 0 END ) AS flag from predict_table) AS Flag table").show()


 

